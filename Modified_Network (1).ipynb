{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Modified Network",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "73tLeZWDCPJ7"
      },
      "source": [
        "\n",
        "#  the model in this file comes from this website\n",
        "\n",
        "#  https://geertlitjens.nl/post/getting-started-with-camelyon/\n",
        "\n",
        "\n",
        "\n",
        "#  without editing the model, it is 80% accurate/confident"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F5Prf7vNT517",
        "colab_type": "code",
        "outputId": "e7ef3d2e-452f-404a-9ee1-05918386c61f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jU5bibOrj4hX",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "pcam, pcam_info = tfds.load('patch_camelyon', shuffle_files=True, with_info=True,\n",
        "                            data_dir='/content/drive/My Drive/Colab Notebooks')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "84yAQsv90JIV",
        "colab": {}
      },
      "source": [
        "# Import NumPy to handle array's and Matplotlib for plotting loss curves\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Import TensorFlow and relevant Keras classes to setup the model\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Dense, Conv2D, MaxPool2D, Flatten, Dropout, BatchNormalization, Activation, LayerNormalization, Cropping2D\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.optimizers import SGD, Adam\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4o2i2JzdrrqX",
        "outputId": "529a0bb1-5720-4977-fab0-04716d0c9cd6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#just some network parameters, see above link regarding the layers for details\n",
        "kernel_size = (3,3)\n",
        "pool_size= (2,2)\n",
        "first_filters = 32\n",
        "second_filters = 64\n",
        "third_filters = 128\n",
        "\n",
        "#dropout is used for regularization here with a probability of 0.3 for conv layers, 0.5 for the dense layer at the end\n",
        "dropout_conv = 0.3\n",
        "dropout_dense = 0.5\n",
        "\n",
        "#initialize the model\n",
        "model = Sequential()\n",
        "\n",
        "#now add layers to it\n",
        "\n",
        "#conv block 1\n",
        "model.add(Conv2D(first_filters, kernel_size, input_shape = (96, 96, 1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(Conv2D(first_filters, kernel_size, use_bias=False))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(MaxPool2D(pool_size = pool_size)) \n",
        "model.add(Dropout(dropout_conv))\n",
        "\n",
        "\n",
        "\n",
        "#conv block 2\n",
        "model.add(Conv2D(second_filters, kernel_size, use_bias=False))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(Conv2D(second_filters, kernel_size, use_bias=False))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(MaxPool2D(pool_size = pool_size))\n",
        "model.add(Dropout(dropout_conv))\n",
        "\n",
        "\n",
        "#conv block 3\n",
        "model.add(Conv2D(third_filters, kernel_size, use_bias=False))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(Conv2D(third_filters, kernel_size, use_bias=False))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(MaxPool2D(pool_size = pool_size))\n",
        "model.add(Dropout(dropout_conv))\n",
        "\n",
        "\n",
        "#a fully connected (also called dense) layer at the end\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256, use_bias=False))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(Dropout(dropout_dense))\n",
        "\n",
        "model.add(Dense(2, activation = \"softmax\"))\n",
        "\n",
        "model.compile(optimizer=Adam(0.001),\n",
        "              loss=tf.keras.losses.binary_crossentropy,\n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_36 (Conv2D)           (None, 94, 94, 32)        320       \n",
            "_________________________________________________________________\n",
            "batch_normalization_42 (Batc (None, 94, 94, 32)        128       \n",
            "_________________________________________________________________\n",
            "activation_42 (Activation)   (None, 94, 94, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_37 (Conv2D)           (None, 92, 92, 32)        9216      \n",
            "_________________________________________________________________\n",
            "batch_normalization_43 (Batc (None, 92, 92, 32)        128       \n",
            "_________________________________________________________________\n",
            "activation_43 (Activation)   (None, 92, 92, 32)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_18 (MaxPooling (None, 46, 46, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_24 (Dropout)         (None, 46, 46, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_38 (Conv2D)           (None, 44, 44, 64)        18432     \n",
            "_________________________________________________________________\n",
            "batch_normalization_44 (Batc (None, 44, 44, 64)        256       \n",
            "_________________________________________________________________\n",
            "activation_44 (Activation)   (None, 44, 44, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_39 (Conv2D)           (None, 42, 42, 64)        36864     \n",
            "_________________________________________________________________\n",
            "batch_normalization_45 (Batc (None, 42, 42, 64)        256       \n",
            "_________________________________________________________________\n",
            "activation_45 (Activation)   (None, 42, 42, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_19 (MaxPooling (None, 21, 21, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_25 (Dropout)         (None, 21, 21, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_40 (Conv2D)           (None, 19, 19, 128)       73728     \n",
            "_________________________________________________________________\n",
            "batch_normalization_46 (Batc (None, 19, 19, 128)       512       \n",
            "_________________________________________________________________\n",
            "activation_46 (Activation)   (None, 19, 19, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_41 (Conv2D)           (None, 17, 17, 128)       147456    \n",
            "_________________________________________________________________\n",
            "batch_normalization_47 (Batc (None, 17, 17, 128)       512       \n",
            "_________________________________________________________________\n",
            "activation_47 (Activation)   (None, 17, 17, 128)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_20 (MaxPooling (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_26 (Dropout)         (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_6 (Flatten)          (None, 8192)              0         \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 256)               2097152   \n",
            "_________________________________________________________________\n",
            "batch_normalization_48 (Batc (None, 256)               1024      \n",
            "_________________________________________________________________\n",
            "activation_48 (Activation)   (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dropout_27 (Dropout)         (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 2)                 514       \n",
            "=================================================================\n",
            "Total params: 2,386,498\n",
            "Trainable params: 2,385,090\n",
            "Non-trainable params: 1,408\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-_4VoQeC_Su",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.python.ops import math_ops\n",
        "from tensorflow.python.framework import ops\n",
        "from tensorflow.python.framework import dtypes\n",
        "from tensorflow.python.ops import array_ops\n",
        "def rgb_to_grayscale2(images, name=None):\n",
        "  \"\"\"Converts one or more images from RGB to Grayscale.\n",
        "  Outputs a tensor of the same `DType` and rank as `images`.  The size of the\n",
        "  last dimension of the output is 1, containing the Grayscale value of the\n",
        "  pixels.\n",
        "  >>> original = tf.constant([[[1.0, 2.0, 3.0]]])\n",
        "  >>> converted = tf.image.rgb_to_grayscale(original)\n",
        "  >>> print(converted.numpy())\n",
        "  [[[1.81...]]]\n",
        "  Args:\n",
        "    images: The RGB tensor to convert. The last dimension must have size 3 and\n",
        "      should contain RGB values.\n",
        "    name: A name for the operation (optional).\n",
        "  Returns:\n",
        "    The converted grayscale image(s).\n",
        "  \"\"\"\n",
        "  with ops.name_scope(name, 'rgb_to_grayscale2', [images]) as name:\n",
        "    images = ops.convert_to_tensor(images, name='images')\n",
        "    # Remember original dtype to so we can convert back if needed\n",
        "    orig_dtype = images.dtype\n",
        "    flt_image = tf.image.convert_image_dtype(images, dtypes.float32)\n",
        "\n",
        "    # Reference for converting between RGB and grayscale.\n",
        "    # https://en.wikipedia.org/wiki/Luma_%28video%29\n",
        "    rgb_weights = [0.2989, 0.5870, 0.1140]\n",
        "    flt_image = math_ops.multiply(flt_image,flt_image)\n",
        "    gray_float = math_ops.tensordot(flt_image, rgb_weights, [-1, -1])\n",
        "    gray_float = tf.math.rsqrt(gray_float)\n",
        "    gray_float = array_ops.expand_dims(gray_float, -1)\n",
        "    return tf.image.convert_image_dtype(gray_float, orig_dtype, name=name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rsNicrTjrruM",
        "colab": {}
      },
      "source": [
        "import random\n",
        "\n",
        "def convert_sample(sample):\n",
        "    image, label = sample['image'], sample['label']  \n",
        "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
        "    #image = tf.image.random_jpeg_quality(image,90,100)\n",
        "    image = tf.image.rot90(image, random.randint(0,3))\n",
        "    image = tf.image.random_flip_left_right(image)\n",
        "\n",
        "    image = tf.image.rgb_to_grayscale(image)\n",
        "\n",
        "    image = tf.image.resize(tf.image.central_crop(image, random.random() / 6), (96,96))\n",
        "    #image2 = tf.image.rgb_to_hsv(image)\n",
        "    #image = tf.image.central_crop(image,.5)\n",
        "    #image2 = rgb_to_grayscale2(image)\n",
        "    #image = tf.concat([image1,image2], axis = 2)\n",
        "    label = tf.one_hot(label, 2, dtype=tf.float32)\n",
        "    return image, label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0vJ3YLIFrryA",
        "colab": {}
      },
      "source": [
        "train_pipeline = pcam['train'].map(convert_sample,\n",
        "                                   num_parallel_calls=8).shuffle(1024).repeat().batch(64).prefetch(2)\n",
        "valid_pipeline = pcam['validation'].map(convert_sample,\n",
        "                                        num_parallel_calls=8).repeat().batch(128).prefetch(2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0jFZD7Hfrr2E",
        "outputId": "dae0c63e-f415-47af-c755-64bcbb819686",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "hist = model.fit(train_pipeline,\n",
        "                 validation_data=valid_pipeline,\n",
        "                 verbose=2, epochs=25, steps_per_epoch=256, validation_steps=256)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "256/256 - 32s - loss: 0.7043 - accuracy: 0.6425 - val_loss: 1.0616 - val_accuracy: 0.4995\n",
            "Epoch 2/25\n",
            "256/256 - 28s - loss: 0.6348 - accuracy: 0.6680 - val_loss: 0.8782 - val_accuracy: 0.4995\n",
            "Epoch 3/25\n",
            "256/256 - 30s - loss: 0.6127 - accuracy: 0.6774 - val_loss: 1.0276 - val_accuracy: 0.5013\n",
            "Epoch 4/25\n",
            "256/256 - 29s - loss: 0.6051 - accuracy: 0.6823 - val_loss: 0.9901 - val_accuracy: 0.5010\n",
            "Epoch 5/25\n",
            "256/256 - 32s - loss: 0.6007 - accuracy: 0.6874 - val_loss: 0.6303 - val_accuracy: 0.6203\n",
            "Epoch 6/25\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FdDV66Lrrr5-",
        "colab": {}
      },
      "source": [
        "test_pipeline = pcam['test'].map(convert_sample, num_parallel_calls=8).batch(128).prefetch(2)\n",
        "print(\"Test set accuracy is {0:.4f}\".format(model.evaluate(test_pipeline, steps=128, verbose=0)[1]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mlu476F7rr-H",
        "colab": {}
      },
      "source": [
        "#model.save(\"./patchcamelyon.hf5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "A3brUq4mrsCS",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}