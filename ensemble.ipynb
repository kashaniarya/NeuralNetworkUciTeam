{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ensemble.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_LTGEzbg_sC",
        "colab_type": "code",
        "outputId": "5d98b864-9b9c-4d34-e52c-8fdc079b7da8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWC54ZZFs5R4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "pcam, pcam_info = tfds.load('patch_camelyon', with_info=True,\n",
        "                            data_dir='/content/drive/My Drive/Colab Notebooks')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MiSHfRwrs7VV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import NumPy to handle array's and Matplotlib for plotting loss curves\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Import TensorFlow and relevant Keras classes to setup the model\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Dense, Conv2D, MaxPool2D, Flatten, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import SGD, Adam\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "#from tensorflow.keras.callbacks import ModelCheckpoint"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fpeTB-5Ys-BT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stacked_models_names = [\"geert\", \"densenet\"]\n",
        "\n",
        "stacked_models = [tf.keras.models.load_model(\"/content/drive/My Drive/Saved/\" + model) for model in stacked_models_names]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQ7WZIV0ImCA",
        "colab_type": "code",
        "outputId": "bec87e4a-6f45-453f-86a7-fb8a198298e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "#First setup the input to the network which has the dimensions of the patches contained within PatchCAMELYON\n",
        "input_shape = Input(shape=(1,2 * len(stacked_models)))\n",
        "\n",
        "# Now we define the layers of the convolutional network: three blocks of two convolutional layers and a max-pool layer.\n",
        "#x = Dense(16, activation='relu')(input_shape)\n",
        "\n",
        "x = Flatten()(input_shape)\n",
        "\n",
        "predictions = Dense(16, activation='relu')(x)\n",
        "\n",
        "predictions = Dense(2, activation='softmax')(x)\n",
        "\n",
        "# Now we define the inputs/outputs of the model and setup the optimizer. In this case we use regular stochastic gradient\n",
        "# descent with Nesterov momentum. The loss we use is cross-entropy and we would like to output accuracy as an additional metric.\n",
        "model = Model(inputs=input_shape, outputs=predictions)\n",
        "sgd_opt = SGD(lr=0.001, momentum=0.9, decay=0.0, nesterov=True)\n",
        "model.compile(optimizer= sgd_opt,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 1, 4)]            0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 4)                 0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 2)                 10        \n",
            "=================================================================\n",
            "Total params: 10\n",
            "Trainable params: 10\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_w6WdTFL0YU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "def convert_sample(sample):\n",
        "    image, label = sample['image'], sample['label']  \n",
        "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
        "    image = tf.image.rot90(image, random.randint(0,3))\n",
        "    image = tf.image.random_flip_left_right(image)\n",
        "    #noise = tf.random.normal(shape=tf.shape(image), mean=0.0, stddev=(.1), dtype=tf.float32) \n",
        "    #image = image + noise\n",
        "    image = tf.expand_dims(image,0)\n",
        "\n",
        "    output =  tf.concat([m(image) for m in stacked_models],1)\n",
        "   \n",
        "\n",
        "    label = tf.one_hot(label, 2, dtype=tf.float32)\n",
        "    return output, label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySUobZBhL2a7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_pipeline = pcam['train'].map(convert_sample,\n",
        "                                   num_parallel_calls=8).shuffle(1024).repeat().batch(64).prefetch(2)\n",
        "valid_pipeline = pcam['validation'].map(convert_sample,\n",
        "                                        num_parallel_calls=8).repeat().batch(128).prefetch(2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7KtVlPQL4kA",
        "colab_type": "code",
        "outputId": "ab96fc26-ba97-46de-dc2f-7f191e7328fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "hist = model.fit(train_pipeline,\n",
        "                 validation_data=valid_pipeline,\n",
        "                 verbose=2, epochs=5, steps_per_epoch=200, validation_steps=256)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "200/200 - 2744s - loss: 0.8162 - accuracy: 0.5157 - val_loss: 0.6406 - val_accuracy: 0.7567\n",
            "Epoch 2/5\n",
            "200/200 - 2778s - loss: 0.5551 - accuracy: 0.8323 - val_loss: 0.5167 - val_accuracy: 0.8145\n",
            "Epoch 3/5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EcScnwVAL_Tz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_pipeline = pcam['test'].map(convert_sample, num_parallel_calls=8).batch(128).prefetch(2)\n",
        "print(\"Test set accuracy is {0:.4f}\".format(model.evaluate(test_pipeline, steps=32768//128, verbose=0)[1]))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}